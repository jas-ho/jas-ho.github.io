---
layout: home
# Index page
---

# Hi there, I'm Jason ğŸ‘‹

- ğŸŒ¸ AI Safety Researcher focused on ensuring AI is used for the common good
- ğŸŒ± Co-Director & Research Lead at [Apart Research](https://apartresearch.com/)
- ğŸ”­ Current research on safety evaluations of large language models
- ğŸ”­ Previous research on text summarization, knowledge graph completion
- ğŸ‘ª Community involvement: [Vienna AI alignment group](https://github.com/ViennaAI/info), [European Network for AI Safety](https://enais.co/)
- ğŸ¤ Looking to collaborate on AI research relevant to AI safety and AI alignment

Feel free to reach out if you'd like to collaborate or discuss AI safety research!

## Connect with me

[![Google Scholar](https://img.shields.io/badge/Google_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white)](https://scholar.google.at/citations?user=FKrb_FwAAAAJ&hl=en)
[![Twitter](https://img.shields.io/badge/X-000000?style=for-the-badge&logo=x&logoColor=white)](https://twitter.com/JasonObermaier)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/jas-ho/)